{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NeuroTimber: Estimating Stacked Timber Volume Using AI Detection and Diameter Distribution Models**"
      ],
      "metadata": {
        "id": "ACc8Kem1emA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary packages"
      ],
      "metadata": {
        "id": "uCbBWKpJdLIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jtlCgpVUibv"
      },
      "outputs": [],
      "source": [
        "!pip install numpy opencv-python-headless torch supervision IPython pandas scipy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the YOLOv9 repository to access the models"
      ],
      "metadata": {
        "id": "fI_koWF0dRnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SkalskiP/yolov9.git\n",
        "%cd yolov9\n",
        "!pip3 install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "H_XNNG9CVV3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from base64 import b64encode\n",
        "import cv2\n",
        "import torch\n",
        "import supervision as sv\n",
        "from models.common import DetectMultiBackend, AutoShape\n",
        "from utils.torch_utils import select_device\n",
        "from utils.general import set_logging\n",
        "from supervision import Detections as BaseDetections\n",
        "from supervision.config import CLASS_NAME_DATA_FIELD\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "qQSpbbZ_U0DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define paths"
      ],
      "metadata": {
        "id": "BIP8aAjzdZ_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = '/content/yolov9-c-wooddetection-converted.pt'\n",
        "data = '/content/wooddetection.yaml'\n",
        "SOURCE_VIDEO_PATH = '/content/Test_Video.mp4'\n",
        "TARGET_VIDEO_PATH = '/content/Demo_Video.mp4'\n",
        "data_path = '/content/dados.xlsx'"
      ],
      "metadata": {
        "id": "H02MnsUMU3TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI Log Detection"
      ],
      "metadata": {
        "id": "zXw8p2ufdrYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extending Supervision's `Detections` to Handle YOLOv9 Results\n",
        "class ExtendedDetections(BaseDetections):\n",
        "    @classmethod\n",
        "    def from_yolov9(cls, yolov9_results) -> 'ExtendedDetections':\n",
        "        xyxy, confidences, class_ids = [], [], []\n",
        "\n",
        "        for det in yolov9_results.pred:\n",
        "            for *xyxy_coords, conf, cls_id in reversed(det):\n",
        "                xyxy.append(torch.stack(xyxy_coords).cpu().numpy())\n",
        "                confidences.append(float(conf))\n",
        "                class_ids.append(int(cls_id))\n",
        "\n",
        "        class_names = np.array([yolov9_results.names[i] for i in class_ids])\n",
        "\n",
        "        if not xyxy:\n",
        "            return cls.empty()\n",
        "\n",
        "        return cls(\n",
        "            xyxy=np.vstack(xyxy),\n",
        "            confidence=np.array(confidences),\n",
        "            class_id=np.array(class_ids),\n",
        "            data={CLASS_NAME_DATA_FIELD: class_names},\n",
        "        )\n",
        "\n",
        "# Loading the Model\n",
        "set_logging(verbose=False)\n",
        "device = select_device('cuda:0')  # Change 'cpu' to 'cuda' to use GPU\n",
        "model = DetectMultiBackend(weights= weights, device=device, data= data, fuse=True)\n",
        "model = AutoShape(model)\n",
        "\n",
        "# Function to Set YOLOv9 Post-processing Parameters\n",
        "def prepare_yolov9(model, conf=0.2, iou=0.7, classes=None, agnostic_nms=False, max_det=1000):\n",
        "    model.conf = conf\n",
        "    model.iou = iou\n",
        "    model.classes = classes\n",
        "    model.agnostic = agnostic_nms\n",
        "    model.max_det = max_det\n",
        "    return model\n",
        "\n",
        "# Function to Play Videos\n",
        "def play(filename, width=500):\n",
        "    html = ''\n",
        "    video = open(filename, 'rb').read()\n",
        "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
        "    html += fr'' % src\n",
        "    return HTML(html)\n",
        "\n",
        "# Constants\n",
        "SOURCE_VIDEO_PATH = SOURCE_VIDEO_PATH\n",
        "TARGET_VIDEO_PATH = TARGET_VIDEO_PATH\n",
        "\n",
        "# Simple Object Detection with YOLOv9 and Supervision\n",
        "def prepare_model_and_video_info(model, config, source_path):\n",
        "    model = prepare_yolov9(model, **config)\n",
        "    video_info = sv.VideoInfo.from_video_path(source_path)\n",
        "    return model, video_info\n",
        "\n",
        "def setup_annotator():\n",
        "    return sv.BoundingBoxAnnotator(thickness=2)\n",
        "\n",
        "def simple_annotate_frame(frame, model, annotator):\n",
        "    frame_rgb = frame[..., ::-1]\n",
        "    results = model(frame_rgb, size=640, augment=False)\n",
        "    detections = ExtendedDetections.from_yolov9(results)\n",
        "\n",
        "    # Annotate the frame with detections\n",
        "    annotated_frame = annotator.annotate(scene=frame.copy(), detections=detections)\n",
        "\n",
        "    return annotated_frame\n",
        "\n",
        "def simple_process_video(model, config=dict(conf=0.1, iou=0.45, classes=None,), source_path=SOURCE_VIDEO_PATH, target_path=TARGET_VIDEO_PATH):\n",
        "    model, _ = prepare_model_and_video_info(model, config, source_path)\n",
        "    annotator = setup_annotator()\n",
        "\n",
        "    def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
        "        return simple_annotate_frame(frame, model, annotator)\n",
        "\n",
        "    sv.process_video(source_path=source_path, target_path=target_path, callback=callback)\n",
        "\n",
        "# Advanced Detection, Tracking, and Counting with YOLOv9 and Supervision\n",
        "\n",
        "class GlobalCounter:\n",
        "    def __init__(self):\n",
        "        self.total_count = 0\n",
        "        self.tracker_ids = set()\n",
        "\n",
        "    def update(self, detections):\n",
        "        for tracker_id in detections.tracker_id:\n",
        "            if tracker_id not in self.tracker_ids:\n",
        "                self.tracker_ids.add(tracker_id)\n",
        "                self.total_count += 1\n",
        "\n",
        "def setup_model_and_video_info(model, config, source_path):\n",
        "    model = prepare_yolov9(model, **config)\n",
        "    video_info = sv.VideoInfo.from_video_path(source_path)\n",
        "    return model, video_info\n",
        "\n",
        "def create_byte_tracker(video_info):\n",
        "    return sv.ByteTrack(track_activation_threshold=0.25, lost_track_buffer=250, minimum_matching_threshold=0.95, frame_rate=video_info.fps)\n",
        "\n",
        "def setup_annotators():\n",
        "    round_box_annotator = sv.RoundBoxAnnotator(thickness=2, color_lookup=sv.ColorLookup.TRACK)\n",
        "    label_annotator = sv.LabelAnnotator(text_scale=0.5, color_lookup=sv.ColorLookup.TRACK)\n",
        "    return round_box_annotator, label_annotator\n",
        "\n",
        "def annotate_frame(frame, index, video_info, detections, byte_tracker, round_box_annotator, label_annotator, show_labels, model, global_counter):\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    # Draw the bounding boxes\n",
        "    annotated_frame = round_box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
        "\n",
        "    # Add labels to the detections\n",
        "    if show_labels:\n",
        "        annotated_frame = add_labels_to_frame(label_annotator, annotated_frame, detections, model)\n",
        "\n",
        "    # Update the global counter and draw it in the top-right corner\n",
        "    global_counter.update(detections)\n",
        "    annotated_frame = draw_counter(annotated_frame, global_counter.total_count)\n",
        "\n",
        "    return annotated_frame\n",
        "\n",
        "def add_labels_to_frame(annotator, frame, detections, model):\n",
        "    labels = [f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\" for confidence, class_id, tracker_id in zip(detections.confidence, detections.class_id, detections.tracker_id)]\n",
        "    return annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "\n",
        "def draw_counter(frame, count):\n",
        "    text = f\"Total Count: {count}\"\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 1\n",
        "    color = (255, 255, 255)\n",
        "    thickness = 2\n",
        "    size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
        "    x = frame.shape[1] - size[0] - 10\n",
        "    y = size[1] + 10\n",
        "    cv2.putText(frame, text, (x, y), font, font_scale, color, thickness)\n",
        "    return frame\n",
        "\n",
        "def process_video(model, config=dict(conf=0.1, iou=0.45, classes=True,), show_labels=True, source_path=SOURCE_VIDEO_PATH, target_path=TARGET_VIDEO_PATH):\n",
        "    model, video_info = setup_model_and_video_info(model, config, source_path)\n",
        "    byte_tracker = create_byte_tracker(video_info)\n",
        "    round_box_annotator, label_annotator = setup_annotators()\n",
        "    global_counter = GlobalCounter()\n",
        "\n",
        "    def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
        "        frame_rgb = frame[..., ::-1]\n",
        "        results = model(frame_rgb, size=608, augment=False)\n",
        "        detections = ExtendedDetections.from_yolov9(results)\n",
        "\n",
        "        # Annotate the frame with detections\n",
        "        annotated_frame = annotate_frame(frame, index, video_info, detections, byte_tracker, round_box_annotator, label_annotator, show_labels, model, global_counter)\n",
        "\n",
        "        return annotated_frame\n",
        "\n",
        "    sv.process_video(source_path=source_path, target_path=target_path, callback=callback)\n",
        "\n",
        "    # Display the total count of logs\n",
        "    print(f\"Total logs counted: {global_counter.total_count}\")\n",
        "\n",
        "    return global_counter.total_count\n",
        "\n",
        "# Detection, Tracking, and Counting in Full Frame\n",
        "yolov9_config=dict(conf=0.3, iou=0.45, classes=[0])\n",
        "total_logs = process_video(model, config=yolov9_config, show_labels=False, target_path= TARGET_VIDEO_PATH)\n",
        "\n",
        "cv2.destroyAllWindows()  # Close all OpenCV windows after processing"
      ],
      "metadata": {
        "id": "28AX7S4yVBat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diameter Distribution Models"
      ],
      "metadata": {
        "id": "xLT6ycSUd-xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data for fitting distributions\n",
        "data_path = data_path\n",
        "data = pd.read_excel(data_path)\n",
        "\n",
        "# Assuming the data is in the first column of the Excel sheet\n",
        "data_column = data.columns[0]\n",
        "data_values = data[data_column].dropna().values\n",
        "\n",
        "# List of specific distributions to check\n",
        "distributions = [\n",
        "    'genextreme', 'powernorm', 'pearson3', 'genhyperbolic', 'johnsonsu', 'truncnorm',\n",
        "    'skewnorm', 'nct', 'gennorm', 'exponnorm', 'norm', 'dweibull', 'dgamma', 't'\n",
        "]\n",
        "\n",
        "# Function to calculate the best fit distributions using AIC\n",
        "def best_fit_distributions(data, distributions, top_n=5):\n",
        "    distribution_scores = []\n",
        "\n",
        "    for distribution in distributions:\n",
        "        dist = getattr(stats, distribution)\n",
        "        try:\n",
        "            params = dist.fit(data)\n",
        "            # Calculate log likelihood\n",
        "            log_likelihood = np.sum(dist.logpdf(data, *params[:-2], loc=params[-2], scale=params[-1]))\n",
        "            # Number of parameters\n",
        "            k = len(params)\n",
        "            # Calculate AIC\n",
        "            aic = 2 * k - 2 * log_likelihood\n",
        "            # Append distribution, parameters, and AIC to the list\n",
        "            distribution_scores.append((dist, params, aic))\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # Sort by AIC and select the top_n distributions\n",
        "    distribution_scores.sort(key=lambda x: x[2])\n",
        "    return distribution_scores[:top_n]\n",
        "\n",
        "# Find the top 5 best fit distributions\n",
        "top_distributions = best_fit_distributions(data_values, distributions, top_n=5)\n",
        "\n",
        "# Print the best distributions and their parameters\n",
        "for i, (dist, params, aic) in enumerate(top_distributions):\n",
        "    print(f'Rank {i+1}: {dist.name} with AIC: {aic}')\n",
        "    print(f'Parameters: {params}')\n",
        "\n",
        "# Prepare to plot the top 5 best fit distributions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(data_values, bins=30, density=True, alpha=0.5, color='b', label='Data')\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "# x_values for calculating probabilities\n",
        "x_values = np.arange(1, 36)\n",
        "\n",
        "# DataFrame to store the probabilities of each distribution\n",
        "results = pd.DataFrame(x_values, columns=['Value'])\n",
        "\n",
        "for i, (dist, params, aic) in enumerate(top_distributions):\n",
        "    p = dist.pdf(x_values, *params[:-2], loc=params[-2], scale=params[-1])\n",
        "    results[f'Rank {i+1}: {dist.name}'] = p\n",
        "    plt.plot(x_values, p, linewidth=2, label=f'Rank {i+1}: {dist.name}')\n",
        "\n",
        "plt.title('Top 5 Best Fit Distributions')\n",
        "plt.xlabel('Data values')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.savefig('/content/top_5_best_fit_distributions.png')  # Save the plot\n",
        "plt.close()  # Close the plot\n",
        "\n",
        "# Save the probabilities to a CSV file\n",
        "results.to_csv('/content/probabilities_top_5.csv', index=False)\n",
        "\n",
        "# Display the results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "eZ2e6ksTVC96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimating Stacked Timber Volume"
      ],
      "metadata": {
        "id": "ipUZxBRyeGPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the estimated volume for each class\n",
        "log_length = 6  # Customize log length as needed\n",
        "total_volume_estimated = 0\n",
        "\n",
        "for index, row in results.iterrows():\n",
        "    class_number = row['Value']\n",
        "    probability = row['Rank 1: genextreme'] # Replace with your distribuition model selected\n",
        "    log_count = total_logs  # Replace with the actual count of logs for this class if available. default: total_logs\n",
        "\n",
        "    # Volume observed for each class\n",
        "    volume_observed = (np.pi / 40000) * (class_number ** 2) * log_length\n",
        "\n",
        "    # Estimated volume for each class\n",
        "    volume_estimated = probability * log_count * volume_observed\n",
        "\n",
        "    total_volume_estimated += volume_estimated\n",
        "\n",
        "print(f'Total estimated volume: {total_volume_estimated} cubic meters')"
      ],
      "metadata": {
        "id": "etVKGMwdVIC0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}